\documentclass[12pt]{article}
\usepackage{amsfonts}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{rotating}
\usepackage{graphics}
\usepackage{epstopdf}
\usepackage{pdfsync}
\usepackage{natbib}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{hyperref}

\textheight 9.2 in \textwidth 6.4 in
\topmargin -0.15 in       % for PC
\topmargin -0.7 in       % for Unix
\oddsidemargin 0.10in %\evensidemargin 0.0in
\parskip=.00in
\renewcommand{\baselinestretch} {1.2}
\makeatletter \setcounter{page}{1}
\def\singlespace{\def\baselinestretch{1}\@normalsize}
\def\endsinglespace{}

\@addtoreset{equation}{section}
\renewcommand{\theequation} {\arabic{section}.\arabic{equation}}
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%


% begin definition
\def\conas{\stackrel{a.s.} {\rightarrow}}         % conv. a.s.
\def\conP{\stackrel{\cal P} {\rightarrow}}        % conv. in probability
\def\conD{\stackrel{\cal D} {\rightsquigarrow}}        % conv. in distribution
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\def\iid{\stackrel{ iid} {\sim}}          % i.i.d
\def\hat{\widehat}
\def\tilde{\widetilde}

%general sets
\def\cal{\mathcal}
\def\calA{{\cal A}} %Action sets
\def\calB{{\cal B}} %Bounded set
\def\calC{{\cal C}} %Convex set
\def\calH{{\cal H}} %Hilbert Space
\def\calS{{\cal S}} %A regular set
\def\calNr{{\cal N}_r} %Neighborhood
\def\calX{{\cal X}} %Covariate space
\def\calF{{\cal F}} %Function space
\def\calQ{{\cal Q}} %Function space
%special sets
\def\bbR{{\mathbb{R}}} %Real number
\def\bbN{{\mathbb{N}}}%Natural number
\def\bbQ{{\mathbb{Q}}} %Rational number
\def\bbZ{{\mathbb{Z}}} %Integer

%Matrix
\def\bA{{\bf A}}
\def\bB{{\bf B}}
\def\bC{{\bf C}}
\def\bD{{\bf D}}
\def\bH{{\bf H}}
\def\bI{{\bf I}}
\def\bJ{{\bf J}}
\def\bP{{\bf P}}
\def\bT{{\bf T}}
\def\bW{{\bf W}}
\def\bX{{\bf X}}

%vector
\def\balpha{{\boldsymbol \alpha}}
\def\bbeta{{\boldsymbol \beta}}
\def\btheta{{\boldsymbol \theta}}

\def\bzero{{\bf 0}}
\def\bone{{\bf 1}}
\def\bbf{{\bf f}}
\def\br{{\bf r}}
\def\by{{\bf y}}

%notations
\def\sign{{\mathrm{sign}}}
\def\var{{\mathrm{var}}}
\def\cov{{\mathrm{cov}}}
\def\ind{\perp\!\!\!\perp}

%others
\def\mif{\mathrm{if}\ }
\def\ow{\mathrm{otherwise}\ }
\def\st{\mathrm{subject\ to}\quad }
\def\diag{\mathrm{diag}}
\def\minimize{\mathrm{minimize}\quad }
\def\maximize{\mathrm{maximize}\quad }
\def\dom{{\rm dom}}

\usepackage{hyperref}

\begin{document}
\title
{\bf My Data Science Challenging Problems \# 52: Clustering and Labeling with Minimal Human Computer Interactions}
\author
{
*** *** ***,***\\
XXX \\
XXXX \\
\textsl{xxx} }
\date{\today}

\maketitle
\begin{abstract}
\textbf{{\color[rgb]{1,0,0} If you happen to have a solution of this question, please contact Haoda Fu at \href{mailto:fu\_haoda@lilly.com }{fu\_haoda@lilly.com} or  \href{mailto:ffuhaoda@gmail.com}{fuhaoda@gmail.com}  or commit your solution to \url{https://github.com/fuhaoda/DCSP52_HumanComputerInteractionClustering.git} }
}

\end{abstract}

\noindent {\bf Key words and Phrases}: *** ***.

\noindent {\bf Short title}: ***
\section{Introduction}
The field of machine learning is faced with a pressing challenge - an enormous amount of unlabeled data, particularly in the medical field. According to estimates, less than 1\% of medical images are currently labeled and ready for supervised machine learning tasks. Labeling data can be time-consuming and requires domain knowledge from experts who may have limited availability. Therefore, it is crucial to develop algorithms that can efficiently use human expert time to label the data. To address this challenge, investment in research and development is essential. Effective algorithms can leverage the expertise of human annotators more efficiently and unlock the vast potential of the available unlabeled data.

Recent research has shown promising results in this area, particularly in the use of active learning, semi-supervised learning, and transfer learning (e.g. our recent JASA paper \href{https://www.tandfonline.com/doi/abs/10.1080/01621459.2021.2019045}{click here}).

We are currently seeking an algorithm capable of handling high-dimensional data such as images, voices, texts, and videos. To make this problem more concrete, we can use the MNIST database as a testbed (\href{https://en.wikipedia.org/wiki/MNIST_database}{click here for reference}). This large labeled database contains 60,000 training images and 10,000 testing images of handwritten digits. Let's remove all the labels for those 60,000 training data to fit our purpose.  Suppose we have only 10 minutes for a person to label the 60,000 images accurately. A naive solution would be to label images one by one, which would take approximately 10 minutes per 600 images. Then, we could train a deep learning algorithm using these 600 labeled images and predict the labels for the remaining 59,400 images. This approach could result in around 80\% accuracy on the entire dataset. How can we do better?

We may quickly indentify some limitations of this naive approach:

\begin{itemize}
	\item This naive approach randomly selected those 600 images and query the human one by one. Can we enable the computer to ask the most relevant questions based on what the algorithm has already learned? 
	\item Labeling one image at a time is not the only query method available. We could also ask whether two images belong to the same class or what the majority class is among 11 images. Each query method ($Q_i$) is associated with a cost ($C_i$) and potentially the probability of correct answers ($p_i$). Therefore, we have a choice of query as $\calQ = \{(Q_i, C_i, p_i), i=1,\cdots, k\}$. 
\end{itemize}


\section{Problem details}


One potential solution that we are exploring is learning a metric that aligns with our labeling objective.

In the ideal case, we could directly apply a non-supervised clustering algorithm, such as the K-means method, and obtain 10 classes for the handwritten zip codes that perfectly correspond to the digits from 0 to 9. Unfortunately, this is not typically the case. The reason is that clustering analysis algorithms, such as K-means and hierarchical clustering, rely on the similarity and dissimilarity between different subjects, i.e. a metric. However, the metric used in clustering methods may not align with our objective of labeling. Therefore, we are investigating methods to iteratively learn a metric that better aligns with our objective and can improve the accuracy of labeling.


Suppose we have subjects $\{X_1,\cdots, X_n\}$. For each subject $X_i$, we have multiple attributes, i.e. $X_i=(X_{i1},\cdots, X_{ip})$ which is a $p$ dimensional vector.  Let $d(X_i, X_j)=\{ (X_i-X_j)^\top A (X_i-X_j) \}^{1/2}$ be the human defined norm which has unknown parameters in a semi-positive definite matrix $A$. We would like to estimate $A$ through human and computer interaction from the following steps. The collection of $ \calA ={A} $ can be considered as a space. 

\begin{enumerate}
	\item Start from a guess, say $A=I$, or some $A$ comes from transfer learning.
	\item Choose a query method from $\calQ$ to query a human.
	\item The result can be denoted as $f(A)$ to measure how good of the current $A$.
	\item Iterate step 2 and step 3 until that the human is happy with the result $A$.  
\end{enumerate}

We need to consider a few things in the above approach, for example, 
\begin{itemize}
	\item How can we know how complex of the space  and what is the current status?
	\item How can we develop a method to choose different types of query? and generate most informative samples corresponding to this query?
	\item How can we develop an optimization algorithm on space $\calA$? 
\end{itemize}


\bibliographystyle{/Users/c082213/BoxSync/Help/References/asa_HD}
\bibliography{/Users/c082213/BoxSync/Help/References/MyStats}


\end{document}
