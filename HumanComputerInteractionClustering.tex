\documentclass[12pt]{article}
\usepackage{amsfonts}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{rotating}
\usepackage{graphics}
\usepackage{epstopdf}
\usepackage{pdfsync}
\usepackage{natbib}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{hyperref}

\textheight 9.2 in \textwidth 6.4 in
\topmargin -0.15 in       % for PC
\topmargin -0.7 in       % for Unix
\oddsidemargin 0.10in %\evensidemargin 0.0in
\parskip=.00in
\renewcommand{\baselinestretch} {1.2}
\makeatletter \setcounter{page}{1}
\def\singlespace{\def\baselinestretch{1}\@normalsize}
\def\endsinglespace{}

\@addtoreset{equation}{section}
\renewcommand{\theequation} {\arabic{section}.\arabic{equation}}
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%


% begin definition
\def\conas{\stackrel{a.s.} {\rightarrow}}         % conv. a.s.
\def\conP{\stackrel{\cal P} {\rightarrow}}        % conv. in probability
\def\conD{\stackrel{\cal D} {\rightsquigarrow}}        % conv. in distribution
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\def\iid{\stackrel{ iid} {\sim}}          % i.i.d
\def\hat{\widehat}
\def\tilde{\widetilde}

%general sets
\def\cal{\mathcal}
\def\calA{{\cal A}} %Action sets
\def\calB{{\cal B}} %Bounded set
\def\calC{{\cal C}} %Convex set
\def\calH{{\cal H}} %Hilbert Space
\def\calS{{\cal S}} %A regular set
\def\calNr{{\cal N}_r} %Neighborhood
\def\calX{{\cal X}} %Covariate space
\def\calF{{\cal F}} %Function space
\def\calQ{{\cal Q}} %Function space
%special sets
\def\bbR{{\mathbb{R}}} %Real number
\def\bbN{{\mathbb{N}}}%Natural number
\def\bbQ{{\mathbb{Q}}} %Rational number
\def\bbZ{{\mathbb{Z}}} %Integer

%Matrix
\def\bA{{\bf A}}
\def\bB{{\bf B}}
\def\bC{{\bf C}}
\def\bD{{\bf D}}
\def\bH{{\bf H}}
\def\bI{{\bf I}}
\def\bJ{{\bf J}}
\def\bP{{\bf P}}
\def\bT{{\bf T}}
\def\bW{{\bf W}}
\def\bX{{\bf X}}

%vector
\def\balpha{{\boldsymbol \alpha}}
\def\bbeta{{\boldsymbol \beta}}
\def\btheta{{\boldsymbol \theta}}

\def\bzero{{\bf 0}}
\def\bone{{\bf 1}}
\def\bbf{{\bf f}}
\def\br{{\bf r}}
\def\by{{\bf y}}

%notations
\def\sign{{\mathrm{sign}}}
\def\var{{\mathrm{var}}}
\def\cov{{\mathrm{cov}}}
\def\ind{\perp\!\!\!\perp}

%others
\def\mif{\mathrm{if}\ }
\def\ow{\mathrm{otherwise}\ }
\def\st{\mathrm{subject\ to}\quad }
\def\diag{\mathrm{diag}}
\def\minimize{\mathrm{minimize}\quad }
\def\maximize{\mathrm{maximize}\quad }
\def\dom{{\rm dom}}

\usepackage{hyperref}

\begin{document}
\title
{\bf My Data Science Challenging Problems \# 52: Clustering and Labeling with Minimal Human Computer Interactions}
\author
{
*** *** ***,***\\
XXX \\
XXXX \\
\textsl{xxx} }
\date{\today}

\maketitle
\begin{abstract}
\textbf{{\color[rgb]{1,0,0} If you happen to have a solution of this question, please contact Haoda Fu at \href{mailto:fu\_haoda@lilly.com }{fu\_haoda@lilly.com} or  \href{mailto:ffuhaoda@gmail.com}{fuhaoda@gmail.com}  or commit your solution to \url{https://github.com/fuhaoda/DCSP52_HumanComputerInteractionClustering.git} }
}

\end{abstract}

\noindent {\bf Key words and Phrases}: *** ***.

\noindent {\bf Short title}: ***
\section{Introduction}
The field of machine learning is faced with a pressing challenge - an enormous amount of unlabeled data, particularly in the medical field. According to estimates, less than 1\% of medical images are currently labeled and ready for supervised machine learning tasks. Labeling data can be time-consuming and requires domain knowledge from experts who may have limited availability. Therefore, it is crucial to develop algorithms that can efficiently use human expert time to label the data. To address this challenge, investment in research and development is essential. Effective algorithms can leverage the expertise of human annotators more efficiently and unlock the vast potential of the available unlabeled data.

Recent research has shown promising results in this area, particularly in the use of active learning, semi-supervised learning, and transfer learning (e.g. our recent JASA paper \href{https://www.tandfonline.com/doi/abs/10.1080/01621459.2021.2019045}{click here}).

We are currently seeking an algorithm capable of handling high-dimensional data such as images, voices, texts, and videos. To make this problem more concrete, we can use the MNIST database as a testbed (\href{https://en.wikipedia.org/wiki/MNIST_database}{click here for reference}). This large labeled database contains 60,000 training images and 10,000 testing images of handwritten digits. Let's remove all the labels for those 60,000 training data to fit our purpose.  Suppose we have only 10 minutes for a person to label the 60,000 images accurately. A naive solution would be to label images one by one, which would take approximately 10 minutes per 600 images. Then, we could train a deep learning algorithm using these 600 labeled images and predict the labels for the remaining 59,400 images. This approach could result in around 80\% accuracy on the entire dataset. How can we do better?

We may quickly indentify some limitations of this naive approach:

\begin{itemize}
	\item This naive approach randomly selected those 600 images and query the human one by one. Can we enable the computer to ask the most relevant questions based on what the algorithm has already learned? 
	\item Labeling one image at a time is not the only query method available. We could also ask whether two images belong to the same class or what the majority class is among 11 images. Each query method ($Q_i$) is associated with a cost ($C_i$) and potentially the probability of correct answers ($p_i$). Therefore, we have a choice of query as $\calQ = \{(Q_i, C_i, p_i), i=1,\cdots, k\}$. 
\end{itemize}


\subsection{Data Labeling}
In healthcare and medical research, majority of data remain unlabeled and it is estimated that labeled data in medical and healthcare industry is less than 2\%, particularly in areas such as medical imaging and electronic health records (EHRs). The labeling of this data is critical for training efficient AI and machine learning (ML) models, which have the potential to drive innovation and improve healthcare quality. Data labeling in healthcare involves categorizing and annotating data to enhance its utility for applications such as clinical research, predictive analytics, personalized medicine, and clinical decision support.

Labeled data is essential for developing accurate AI/ML models that can support healthcare applications, including early disease detection, treatment planning, and decision-making. As the demand for healthcare analytics and AI-driven solutions grows, so does the need for high-quality labeled data. Specialized labeling tasks, such as medical coding, clinical entity recognition, and image annotation, are crucial for transforming raw data into actionable insights. Accurate data labeling not only improves the performance of AI/ML models but also enables advancements in clinical decision support, medical research, and population health management.

Labeling data in the medical and healthcare fields often requires specialized expertise, such as knowledge of pathology for interpreting CT scans. Experts typically require years of training to acquire this knowledge, which creates a fundamental challenge: while there is a large volume of unlabeled data, there is limited time available for experts to dedicate to labeling. For instance, in the context of labeling medical images, although the time spent labeling each image may be consistent, not every labeled image contributes equally to improving model performance. This raises a critical question: how can we effectively utilize expert time to label data in a way that maximizes the efficiency of model training?

To illustrate this research problem, consider the MNIST dataset of handwritten digits, which consists of 70,000 images of digits ranging from 0 to 9, often used for training various machine learning models. In our scenario, we have the data represented as \(\{(X_i, y_i), i=1, \ldots, 70,000\}\). Suppose we do not know the true labels \(y_i\), and our task is to interactively and iteratively engage a human expert to label a selection of these images \(X_i\) in order to achieve the highest possible accuracy across all 70,000 images. Assuming that computational time is negligible and we have limited expert time—say, 10 minutes—what would be the best strategy for labeling? 

One naive approach would involve asking the expert to label images randomly, one after another. If we assume that it takes approximately one second for a person to label a single image, then within 10 minutes, they could label about 600 images. However, this method is far from optimal. A more efficient strategy could involve allowing the expert to label an initial set of 300 images, after which we train a preliminary model. Using this model, we could then propose an additional 300 images that the model identifies as most informative for improving its performance. Intuitively, this second approach is likely to yield better results than the first. Furthermore, we could enhance the labeling process by enabling the model to ask different types of questions, such as whether a group of five images belongs to the same category or whether two images depict the same digit. Our research question focuses on developing an efficient strategy that facilitates human-computer interaction, allowing us to extract the most valuable information from experts by posing the most effective questions.

One potential solution we are exploring involves learning a metric that aligns with our labeling objective.

Ideally, we could directly apply a non-supervised clustering algorithm, such as the K-means method, to obtain 10 classes for the handwritten zip codes that perfectly correspond to the digits from 0 to 9. Unfortunately, this is often not the case. The challenge arises because clustering algorithms, including K-means and hierarchical clustering, depend on the similarity and dissimilarity between different subjects, which is determined by a metric. However, the metric used in clustering methods may not align with our labeling objectives. Therefore, we are investigating methods to iteratively learn a metric that better aligns with our goals and improves labeling accuracy.

Suppose we have a set of subjects \(\{X_1, \ldots, X_n\}\). For each subject \(X_i\), we have multiple attributes, represented as \(X_i = (X_{i1}, \ldots, X_{ip})\), which forms a \(p\)-dimensional vector. Let \(d(X_i, X_j) = \{(X_i - X_j)^\top A (X_i - X_j)\}^{1/2}\) be the human-defined norm, where \(A\) is a semi-positive definite matrix with unknown parameters. Our goal is to estimate \(A\) through human-computer interaction using the following steps. The collection of \(\mathcal{A} = \{A\}\) can be considered as a space.

\begin{enumerate}
    \item Start from an initial guess, such as \(A = I\) or some \(A\) derived from transfer learning.
    \item Choose a query method from \(\mathcal{Q}\) to query a human expert.
    \item The result can be denoted as \(f(A)\) to measure the quality of the current \(A\).
    \item Iterate steps 2 and 3 until the human expert is satisfied with the resulting \(A\).  
\end{enumerate}

In this approach, we need to consider several factors:
\begin{itemize}
    \item How can we assess the complexity of the space and the current status? For example, if we had a progress bar, we could employ different strategies.
    \item How can we develop a method to select different types of queries and generate the most informative samples corresponding to these queries?
    \item How can we formulate an optimization algorithm over the space \(\mathcal{A}\)?
\end{itemize}

It is important to note that the metric described above is linear, and we should also explore more sophisticated metrics for complex problems. 

This problem is sufficiently general, and we anticipate that the solution can be applied across a diverse range of fields. Potential application areas include image labeling and segmentation, natural language processing, video labeling, and even medical diagnostics. Beyond these, our approach could also benefit domains such as autonomous driving—where accurate labeling of images is crucial for training models to identify pedestrians, vehicles, and traffic signs—environmental monitoring through satellite imagery analysis, and social media sentiment analysis. By addressing the challenge of efficient metric learning, we aim to enhance model performance and streamline data labeling processes across these varied applications, ultimately driving innovation and improving outcomes in each field.




\bibliographystyle{/Users/c082213/BoxSync/Help/References/asa_HD}
\bibliography{/Users/c082213/BoxSync/Help/References/MyStats}


\end{document}
